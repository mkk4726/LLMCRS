{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt design in LLMCRS\n",
    "\n",
    "prompt_subtask_detection = f'''The AI assistant should analyze the dialogue context to detect which sub-task should be selected. The sub- tasks include: { subtask_lists }. The selected sub-task need to represent by its corresponding sub-task schema. The sub-task schema is { subtask_schema_json }. There are some cases for your reference: { Demonstrations }. The dialogue context is { Dialogue_Context }. From this dialogue context, which sub-task should be selected? The sub-task MUST be selected from the above list and represented by the schema.'''\n",
    "prompt_model_matching = f'''The AI assistant should select the most appropriate expert model to process the sub-task based on the sub- task goal and expert model description. The sub-task goal is { SubTask_Goal }. The list of expert models is { [ID, Description] }. Please select one expert model. The expert model MUST be selected from the above list and represented by the ID.'''\n",
    "prompt_response_generation = f'''With the dialogue context and the sub-task results, the AI assistant needs to generate a response to the user. The dialogue context is { Dialogue_Context }. The sub-task results can be formed as: Sub-Task Name: { SubTask_Name }, Expert Model: { ID, Description }, and Sub- Task Output: { Output }. Please generate a response to answer the user’s request.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) schema instruction\n",
    "\n",
    "- subtask manager의 역할\n",
    "- subtask 종류\n",
    "- subtask 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask_lists = '[ User preference elicitation, Recommendation, Explanation, Item detail search ]'\n",
    "\n",
    "subtask_schema_table = '''\n",
    "1) Sub-task name: It provides a unique identifier for sub-task detection, which is used for references to related expert models and their predicted results.\n",
    "2) Sub-task arguments: It contains the list of required arguments for sub-task execution. They are resolved from either the dia- logue context or the predicted results of the sub-tasks executed in the previous dialogue turns.\n",
    "3) Output type: It indicates the type of the outputs of the sub-task.\n",
    "\n",
    "| Sub Task Name | Sub-Task Arguments | Output type |\n",
    "| ———————— | ——————————- | ——————- |\n",
    "| User preference elicitation | {category, dialogue context} | Text |\n",
    "| Recommendation | {category, dialogue context} | Item |\n",
    "| Explanation | {item name, dialogue context} | Text |\n",
    "| Item detail search | {item name, item attribute} | Text |\n",
    "'''\n",
    "\n",
    "subtask_schema_json = \"\"\"1) Sub-task name: It provides a unique identifier for sub-task detection, which is used for references to related expert models and their predicted results.\n",
    "2) Sub-task arguments: It contains the list of required arguments for sub-task execution. They are resolved from either the dia- logue context or the predicted results of the sub-tasks executed in the previous dialogue turns.\n",
    "3) Output type: It indicates the type of the outputs of the sub-task.\n",
    "\n",
    "[{'subtask name': 'user preference elicitation', 'subtask arguments': ['category', 'dialogue context'], 'output type':'text'},\n",
    "{'subtask name': 'recommendation', 'subtask arguments': ['category','dialogue context'], 'output type': 'item'},\n",
    "{'subtask name': 'explanation', 'subtask arguements': ['item name', 'dialogue context'], 'output type': 'text'},\n",
    "{'subtask name': 'item detail search', 'subtask arguments': ['item name', 'item attribute'], 'output type': 'text'}]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstraion_instruction = '''user_query: I want to find a legal drama\n",
    "answer: \n",
    "    subtask name: user preference elicitation,\n",
    "    subtask arguments: [\"legal drama\", \"I want to find a legal drama\"],\n",
    "    output type: text\n",
    "\n",
    "user_query: I want the female actor as the lead role\n",
    "answer:\n",
    "    \"subtask name\": \"recommendation\",\n",
    "    \"subtask arguments\": [\"legal drama\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"item\"\n",
    "\n",
    "user_query: Why do you recommend it to me?\n",
    "answer:\n",
    "    \"subtask name\": \"explanation\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"text\"\n",
    "\n",
    "user_query: OK. what timeframe is it?\n",
    "answer:\n",
    "    \"subtask name\": \"item detail research\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\\nOK. Why do you recommend it to me?\\nWhat timeframe is it?\"],\n",
    "    \"output type\": \"item\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask_detection_prompt = '''The AI assistant should analyze the dialogue context to detect which sub-task should be selected.\n",
    "The subtasks include: {subtask_lists}.\n",
    "The subtask schema is {subtask_schema}.\n",
    "The selected sub-task need to represent by its corresponding sub-task schema.\n",
    "\n",
    "There are some cases for your reference.\n",
    "\n",
    "user_query: I want to find a legal drama\n",
    "answer: \n",
    "    subtask name: user preference elicitation,\n",
    "    subtask arguments: [\"legal drama\", \"I want to find a legal drama\"],\n",
    "    output type: text\n",
    "\n",
    "user_query: I want the female actor as the lead role\n",
    "answer:\n",
    "    \"subtask name\": \"recommendation\",\n",
    "    \"subtask arguments\": [\"legal drama\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"item\"\n",
    "\n",
    "user_query: Why do you recommend it to me?\n",
    "answer:\n",
    "    \"subtask name\": \"explanation\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"text\"\n",
    "\n",
    "user_query: OK. what timeframe is it?\n",
    "answer:\n",
    "    \"subtask name\": \"item detail research\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\\nOK. Why do you recommend it to me?\\nWhat timeframe is it?\"],\n",
    "    \"output type\": \"item\"\n",
    "\n",
    "Which sub-task should be selected? The sub-task MUST be selected from the above list and represented by the schema.\n",
    "user_query: {query}\n",
    "answer:\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subtask_lists': '[ User preference elicitation, Recommendation, Explanation, Item detail search ]', 'subtask_schema': \"1) Sub-task name: It provides a unique identifier for sub-task detection, which is used for references to related expert models and their predicted results.\\n2) Sub-task arguments: It contains the list of required arguments for sub-task execution. They are resolved from either the dia- logue context or the predicted results of the sub-tasks executed in the previous dialogue turns.\\n3) Output type: It indicates the type of the outputs of the sub-task.\\n\\n[{'subtask name': 'user preference elicitation', 'subtask arguments': ['category', 'dialogue context'], 'output type':'text'},\\n{'subtask name': 'recommendation', 'subtask arguments': ['category','dialogue context'], 'output type': 'item'},\\n{'subtask name': 'explanation', 'subtask arguements': ['item name', 'dialogue context'], 'output type': 'text'},\\n{'subtask name': 'item detail search', 'subtask arguments': ['item name', 'item attribute'], 'output type': 'text'}]\", 'query': 'I need movies with hell lot of dopamine', 'text': '{\\n    \"subtask name\": \"user preference elicitation\",\\n    \"subtask arguments\": [\"dopamine\", \"I need movies with hell lot of dopamine\"],\\n    \"output type\": \"text\"\\n}'}\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "\n",
    "manager = ChatOpenAI(\n",
    "    model = 'gpt-4o-mini',\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "subtask_detection = PromptTemplate(\n",
    "    template  = subtask_detection_prompt ,\n",
    "    input_variables = ['subtask_lists', 'subtask_schema', 'query']\n",
    ")\n",
    "\n",
    "\n",
    "# Chain 정의하기\n",
    "chain = LLMChain(\n",
    "    llm = manager,\n",
    "    prompt = subtask_detection\n",
    ")\n",
    "\n",
    "\n",
    "result = chain.invoke({'subtask_lists': subtask_lists, 'subtask_schema': subtask_schema_json, 'query': 'I need movies with hell lot of dopamine'}) # chain 실행\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"subtask name\": \"user preference elicitation\",\n",
      "    \"subtask arguments\": [\"dopamine\", \"I need movies with hell lot of dopamine\"],\n",
      "    \"output type\": \"text\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''The AI assistant should analyze the dialogue context to detect which sub-task should be selected.\n",
    "The subtasks include: {subtask_lists}.\n",
    "The subtask schema is {subtask_schema}.\n",
    "The selected sub-task need to represent by its corresponding sub-task schema.\n",
    "\n",
    "There are some cases for your reference.\n",
    "\n",
    "user_query: I want to find a legal drama\n",
    "answer: \n",
    "    subtask name: user preference elicitation,\n",
    "    subtask arguments: [\"legal drama\", \"I want to find a legal drama\"],\n",
    "    output type: text\n",
    "\n",
    "user_query: I want the female actor as the lead role\n",
    "answer:\n",
    "    \"subtask name\": \"recommendation\",\n",
    "    \"subtask arguments\": [\"legal drama\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"item\"\n",
    "\n",
    "user_query: Why do you recommend it to me?\n",
    "answer:\n",
    "    \"subtask name\": \"explanation\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\"],\n",
    "    \"output type\": \"text\"\n",
    "\n",
    "user_query: OK. what timeframe is it?\n",
    "answer:\n",
    "    \"subtask name\": \"item detail research\",\n",
    "    \"subtask arguments\": [\"Suits\", \"I want to find a legal drama\\nI want the female actor as the lead role\\nOK. Why do you recommend it to me?\\nWhat timeframe is it?\"],\n",
    "    \"output type\": \"item\"\n",
    "\n",
    "Which sub-task should be selected? The sub-task MUST be selected from the above list and represented by the schema.'''\n",
    "\n",
    "user_messsage = '''\n",
    "user_query: {query}\n",
    "answer:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n    \"subtask name\": \"user preference elicitation\",\\n    \"subtask arguments\": [\"movies with high dopamine\", \"I need movies with hell lot of dopamine\"],\\n    \"output type\": \"text\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 572, 'total_tokens': 616}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-bdf1a9a9-e555-4e08-9776-0de7f458ff51-0', usage_metadata={'input_tokens': 572, 'output_tokens': 44, 'total_tokens': 616})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"user_query: I need movies with hell lot of dopamine\\nanswer:\"\n",
    "            )\n",
    "        ],\n",
    "        'subtask_lists': subtask_lists,\n",
    "        'subtask_schema': subtask_schema_json,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Expert Model Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_lists = \"[ ‘BERT’, ‘GPT-2’, ‘ReDial’, ‘KBRD’, ‘KGSF’, ‘TG-ReDial’ ]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMCRS",
   "language": "python",
   "name": "llmcrs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
